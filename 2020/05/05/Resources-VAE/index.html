<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>

  <!-- Default Mathjax Support -->
<!--   <script type="text/x-mathjax-config">
     MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
          tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
          TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
          messageStyle: "none"
      }); 
  </script>
  <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for(i=0; i < all.length; i += 1) {
              all[i].SourceElement().parentNode.className += ' has-jax';
          }
      });
  </script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->

  
  <title>Resources： VAE | Hako</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="VAE VAE 最通常联系的topic有：  Disentangled Representation Learning. Image Generation. 趋势是VAE和GAN模型的融合，优势互补。">
<meta property="og:type" content="article">
<meta property="og:title" content="Resources： VAE">
<meta property="og:url" content="mercurixito.github.io/2020/05/05/Resources-VAE/index.html">
<meta property="og:site_name" content="Hako">
<meta property="og:description" content="VAE VAE 最通常联系的topic有：  Disentangled Representation Learning. Image Generation. 趋势是VAE和GAN模型的融合，优势互补。">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2020-05-05T14:43:07.000Z">
<meta property="article:modified_time" content="2020-06-14T02:56:11.627Z">
<meta property="article:author" content="Victor Chen">
<meta property="article:tag" content="VAE">
<meta property="article:tag" content="resources">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hako" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hako</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="mercurixito.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Resources-VAE" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/05/05/Resources-VAE/" class="article-date">
  <time datetime="2020-05-05T14:43:07.000Z" itemprop="datePublished">2020-05-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Resources： VAE
    </h1>
  

      </header>
    
    <div class="article-new-date">
	<span> 
	  发布时间: <time datetime="2020-05-05T14:43:07.000Z" itemprop="datePublished">2020-05-05</time>
	   | 
	  最近更新: <time datetime="2020-06-14T02:56:11.627Z" itemprop="datePublished">2020-06-14</time>
  	</span>
</div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="vae"><a class="markdownIt-Anchor" href="#vae"></a> VAE</h2>
<p>VAE 最通常联系的topic有：</p>
<ul>
<li>Disentangled Representation Learning.</li>
<li>Image Generation. 趋势是VAE和GAN模型的融合，优势互补。</li>
</ul>
<a id="more"></a>
<h3 id="unsorted"><a class="markdownIt-Anchor" href="#unsorted"></a> unsorted</h3>
<ul>
<li>AutoEncoding Variational Bayes. <a href="https://arxiv.org/abs/1312.6114" target="_blank" rel="noopener">[paper]</a>  (<strong>Origninal Paper 1</strong>).</li>
<li>Stochastic backpropagation and approximate inference in deep generative models. <a href="https://arxiv.org/abs/1401.4082" target="_blank" rel="noopener">[paper]</a> (<strong>Origninal Paper 2</strong>)</li>
<li>Tutorial on Variational Autoencoders. <a href="https://arxiv.org/abs/1606.05908" target="_blank" rel="noopener">[paper]</a> CMU和UCB的VAE的学习材料，阐述了基本的VAE思想，还包括CVAE的内容。</li>
<li>Learning Structured Output Representation using Deep Conditional Generative Models. <a href="http://papers.nips.cc/paper/5775-learning-structured-output-representation-using-deep-conditional-generative-models.pdf" target="_blank" rel="noopener">[paper]</a> (<strong>CVAE</strong>)。</li>
<li>Adversarial AutoEncoder. <a href="https://arxiv.org/abs/1511.05644" target="_blank" rel="noopener">[paper]</a> (<strong>AAE</strong>)</li>
<li>Wasserstein Auto-Encoders. <a href="https://arxiv.org/abs/1711.01558" target="_blank" rel="noopener">[paper]</a></li>
<li>Adversarial Latent Autoencoders. <a href="https://arxiv.org/abs/2004.04467" target="_blank" rel="noopener">[paper]</a> (<strong>ALAE</strong>) 近来火热的SOTA人脸生成模型。</li>
</ul>
<h3 id="disentangled-representation-learning"><a class="markdownIt-Anchor" href="#disentangled-representation-learning"></a> Disentangled Representation Learning</h3>
<p>见<a href="https://mercurixito.github.io/2020/03/30/Resources-Disentangled-Representation-Learning/">另一篇总结文章</a></p>
<h3 id="sparsity-problem"><a class="markdownIt-Anchor" href="#sparsity-problem"></a> Sparsity Problem</h3>
<p>Sparsity Problem是VAE类模型的常见问题：VAE的编码器仅使用隐变量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">{z}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span></span></span></span></span>的小子集。这在《Deep Learning》一书中也被提及到。该问题也被理解为VAE模型会自剪枝(self-pruning)、过剪枝(over-pruning)、后验坍缩(posterior collapse)问题。</p>
<p>和隐变量探索(latent variable collapse)区分开：隐变量探索指的是当近似后验完全和先验高斯相等时，近似后验完全和输入无关，什么也学不到。</p>
<p>这或许是VAE类模型用于多模态数据建模的正常现象？</p>
<ul>
<li>Importance Weighted Autoencoders. <a href="https://arxiv.org/abs/1509.00519" target="_blank" rel="noopener">[paper]</a> !!!</li>
<li>Tackling Over-pruning in Variational Autoencoders. <a href="https://arxiv.org/abs/1706.03643" target="_blank" rel="noopener">[paper]</a> !!!</li>
<li>Sparsity in Variational Autoencoders。 <a href="https://arxiv.org/abs/1812.07238" target="_blank" rel="noopener">[paper]</a> !!!</li>
<li>Variational Autoencoders and the Variable<br />
Collapse Phenomenon. <a href="https://www.sensorsportal.com/HTML/DIGEST/june_2019/Vol_234/P_3085.pdf" target="_blank" rel="noopener">[paper]</a> 这和上面是同一篇文章。</li>
<li>Redundancy-resistant Generative Hashing for Image Retrieval. <a href="https://www.ijcai.org/Proceedings/2018/0696.pdf" target="_blank" rel="noopener">[paper]</a> !!</li>
</ul>
<h4 id="likely"><a class="markdownIt-Anchor" href="#likely"></a> Likely</h4>
<ul>
<li>Variance Loss in Variational Autoencoders. <a href="https://arxiv.org/abs/2002.09860" target="_blank" rel="noopener">[paper]</a></li>
<li>Don’t Blame the ELBO! A Linear VAE Perspective on Posterior Collapse. <a href="http://papers.nips.cc/paper/9138-dont-blame-the-elbo-a-linear-vae-perspective-on-posterior-collapse" target="_blank" rel="noopener">[paper]</a> !!</li>
<li>Improved Variational Inference with Inverse Autoregressive Flow. <a href="http://papers.nips.cc/paper/6581-improved-variational-inference-with-inverse-autoregressive-flow" target="_blank" rel="noopener">[paper]</a> 同时本文也是Kingma本人的一作。 !</li>
<li>Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders. <a href="https://arxiv.org/abs/1611.02648" target="_blank" rel="noopener">[paper]</a> 这篇文章或许关注了该问题的出现是因为VAE对多模态数据建模？ !!</li>
<li>Avoiding Latent Variable Collapse With Generative Skip Models. <a href="https://arxiv.org/abs/1807.04863" target="_blank" rel="noopener">[paper]</a> 通过加入skip-connection的结构缓解问题。</li>
<li>Lagging Inference Networks and Posterior Collapse in Variational Autoencoders. <a href="https://arxiv.org/abs/1901.05534" target="_blank" rel="noopener">[paper]</a> 认为后验坍缩是因为在训练的早期阶段，encoder推断的近似后验落后于真实后导验致的。</li>
<li>Generating sentences from a continuous space. <a href="https://arxiv.org/abs/1511.06349" target="_blank" rel="noopener">[paper]</a> 其中3.1小节涉及到解决后验坍缩问题。</li>
<li>How to train deep variational autoencoders and probabilistic ladder networks. <a href="https://backend.orbit.dtu.dk/ws/portalfiles/portal/121765928/1602.02282.pdf" target="_blank" rel="noopener">[paper]</a> 在Dissucsion的<code>Latent Representation</code>中涉及到sparse问题。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="mercurixito.github.io/2020/05/05/Resources-VAE/" data-id="ckb3tdmi2001px4uch2nz1z74" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/VAE/" rel="tag">VAE</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/resources/" rel="tag">resources</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/05/08/RP-TCVAE/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          论文阅读： Isolating Sources of Disentanglement in VAEs
        
      </div>
    </a>
  
  
    <a href="/2020/05/01/RP-betaVAE/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">论文阅读： ${beta}$-VAE： Learning Basic Visual Concepts with a constrained variational framework.</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最近更新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/07/17/Stereo-200717/">基于双目视觉的景深估计</a>
          </li>
        
          <li>
            <a href="/2020/07/17/SPM-200717/">基于BoW特征的图像分类(1)</a>
          </li>
        
          <li>
            <a href="/2020/07/17/SPM2-200717/">基于BoW特征的图像分类(2) —— 空间金字塔匹配</a>
          </li>
        
          <li>
            <a href="/2020/06/26/RP-200626-FewLabels/">Weekly Paper： Disentangling Factors of Variatons Using Few Labels</a>
          </li>
        
          <li>
            <a href="/2020/06/21/RP-200621-ALAE/">每日文章： Adversarial Latent Autoencoders</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/APAD/" rel="tag">APAD</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/AutoEncoder/" rel="tag">AutoEncoder</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Disentangled-Representation-Learning/" rel="tag">Disentangled Representation Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GAN/" rel="tag">GAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linear-Algebra/" rel="tag">Linear Algebra</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mathematic/" rel="tag">Mathematic</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Object-Detection/" rel="tag">Object Detection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Paper-Reading/" rel="tag">Paper Reading</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Probability/" rel="tag">Probability</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spatial-Pyramid-Matching/" rel="tag">Spatial Pyramid Matching</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VAE/" rel="tag">VAE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/disentanglement/" rel="tag">disentanglement</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/information-theory/" rel="tag">information theory</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mathematics/" rel="tag">mathematics</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/metrics/" rel="tag">metrics</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/resources/" rel="tag">resources</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/topic-sorted/" rel="tag">topic sorted</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/two-frame-stereo/" rel="tag">two-frame stereo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/unsupervised-gan-controlling/" rel="tag">unsupervised gan controlling</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9D%82%E8%B0%88/" rel="tag">杂谈</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/APAD/" style="font-size: 16.67px;">APAD</a> <a href="/tags/AutoEncoder/" style="font-size: 10px;">AutoEncoder</a> <a href="/tags/Disentangled-Representation-Learning/" style="font-size: 18.33px;">Disentangled Representation Learning</a> <a href="/tags/GAN/" style="font-size: 20px;">GAN</a> <a href="/tags/Linear-Algebra/" style="font-size: 10px;">Linear Algebra</a> <a href="/tags/Mathematic/" style="font-size: 11.67px;">Mathematic</a> <a href="/tags/Object-Detection/" style="font-size: 11.67px;">Object Detection</a> <a href="/tags/Paper-Reading/" style="font-size: 16.67px;">Paper Reading</a> <a href="/tags/Probability/" style="font-size: 10px;">Probability</a> <a href="/tags/Spatial-Pyramid-Matching/" style="font-size: 10px;">Spatial Pyramid Matching</a> <a href="/tags/VAE/" style="font-size: 18.33px;">VAE</a> <a href="/tags/disentanglement/" style="font-size: 11.67px;">disentanglement</a> <a href="/tags/information-theory/" style="font-size: 10px;">information theory</a> <a href="/tags/mathematics/" style="font-size: 10px;">mathematics</a> <a href="/tags/metrics/" style="font-size: 11.67px;">metrics</a> <a href="/tags/resources/" style="font-size: 13.33px;">resources</a> <a href="/tags/topic-sorted/" style="font-size: 11.67px;">topic sorted</a> <a href="/tags/two-frame-stereo/" style="font-size: 10px;">two-frame stereo</a> <a href="/tags/unsupervised-gan-controlling/" style="font-size: 15px;">unsupervised gan controlling</a> <a href="/tags/%E6%9D%82%E8%B0%88/" style="font-size: 13.33px;">杂谈</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">七月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">六月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">五月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">四月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">三月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">十月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">九月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">五月 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/07/17/SPM2-200717/">基于BoW特征的图像分类(2) —— 空间金字塔匹配</a>
          </li>
        
          <li>
            <a href="/2020/07/17/Stereo-200717/">基于双目视觉的景深估计</a>
          </li>
        
          <li>
            <a href="/2020/07/17/SPM-200717/">基于BoW特征的图像分类(1)</a>
          </li>
        
          <li>
            <a href="/2020/06/26/RP-200626-FewLabels/">Weekly Paper： Disentangling Factors of Variatons Using Few Labels</a>
          </li>
        
          <li>
            <a href="/2020/06/21/RP-200621-ALAE/">每日文章： Adversarial Latent Autoencoders</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Victor Chen<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a><br>
      banner image from <a href="https://www.pixiv.net/artworks/80036479" target="_blank">This</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>